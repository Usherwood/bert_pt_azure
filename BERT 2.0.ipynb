{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\usherwoodpe\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform([3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a GPU available: \n",
      "True\n",
      "Is the Tensor on GPU #0:  \n",
      "True\n",
      "Device name: /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Is there a GPU available: \"),\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "print(\"Is the Tensor on GPU #0:  \"),\n",
    "print(x.device.endswith('GPU:0'))\n",
    "\n",
    "print(\"Device name: {}\".format((x.device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to system, local or mounted S3 bucket, e.g. /dbfs/mnt/<path_to_bucket>\n",
    "sys.path.append(os.path.join(os.getcwd(),\"bert\"))\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import logging\n",
    "from collections import Counter\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import modeling, optimization, tokenization\n",
    "from run_pretraining import input_fn_builder, model_fn_builder\n",
    "\n",
    "from text_preprocessing import tokenizer_word\n",
    "from language_model_processing import read_raw_data_preprocess_and_save, create_vocab_df\n",
    "from bpe import create_token_vocabulary, get_stats, merge_vocab, Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 31503\n",
      "{'attention_probs_dropout_prob': 0.1, 'directionality': 'bidi', 'hidden_act': 'gelu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'intermediate_size': 3072, 'max_position_embeddings': 512, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'pooler_fc_size': 768, 'pooler_num_attention_heads': 12, 'pooler_num_fc_layers': 3, 'pooler_size_per_head': 128, 'pooler_type': 'first_token_transform', 'type_vocab_size': 2, 'vocab_size': 31503}\n"
     ]
    }
   ],
   "source": [
    "language_maps_dir = \"models/base/master/language_maps/\"\n",
    "\n",
    "def save_obj(obj, directory, name):\n",
    "    with open(directory / \"{}.pkl\".format(name), 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name, directory):\n",
    "    with open(os.path.join(directory, name + '.pkl'), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "      \n",
    "vocab_to_id = load_obj('vocab_to_id', str(language_maps_dir))\n",
    "print('Vocab Size:', len(vocab_to_id))\n",
    "\n",
    "import json\n",
    "\n",
    "bert_base_config = {\n",
    "  \"attention_probs_dropout_prob\": 0.1, \n",
    "  \"directionality\": \"bidi\", \n",
    "  \"hidden_act\": \"gelu\", \n",
    "  \"hidden_dropout_prob\": 0.1, \n",
    "  \"hidden_size\": 768, \n",
    "  \"initializer_range\": 0.02, \n",
    "  \"intermediate_size\": 3072, \n",
    "  \"max_position_embeddings\": 512, \n",
    "  \"num_attention_heads\": 12, \n",
    "  \"num_hidden_layers\": 12, \n",
    "  \"pooler_fc_size\": 768, \n",
    "  \"pooler_num_attention_heads\": 12, \n",
    "  \"pooler_num_fc_layers\": 3, \n",
    "  \"pooler_size_per_head\": 128, \n",
    "  \"pooler_type\": \"first_token_transform\", \n",
    "  \"type_vocab_size\": 2, \n",
    "  \"vocab_size\": len(vocab_to_id)\n",
    "}\n",
    "\n",
    "with open(os.path.join(language_maps_dir, 'bert_config.json'), 'w') as f:\n",
    "    json.dump(bert_base_config, f)\n",
    "    \n",
    "print(bert_base_config)\n",
    "####################################load_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OlÃ¡ isso Ã© mais uma BAGUNCA ðŸ˜‚ðŸ˜‚ðŸ˜‚\n",
      "['olÃ¡', 'isso', 'Ã©', 'mais', 'uma', 'bagun', 'ca', 'ðŸ˜‚', 'ðŸ˜‚', 'ðŸ˜‚']\n"
     ]
    }
   ],
   "source": [
    "import modeling, optimization, tokenization\n",
    "\n",
    "testcase = \"OlÃ¡ isso Ã© mais uma BAGUNCA ðŸ˜‚ðŸ˜‚ðŸ˜‚\"\n",
    "bert_tokenizer = tokenization.FullTokenizer(language_maps_dir)\n",
    "print(testcase)\n",
    "print(bert_tokenizer.tokenize(testcase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_dir = \"models/base/master/model_weights/\"\n",
    "pretraining_data_dir = 'models/base/master/pretraining_base_data'\n",
    "\n",
    "VOCAB_FILE = language_maps_dir + '/vocab_file.csv'\n",
    "CONFIG_FILE = language_maps_dir + '/bert_config.json'\n",
    "\n",
    "INIT_CHECKPOINT = tf.train.latest_checkpoint(model_weights_dir)\n",
    "\n",
    "MINI_BATCH_SIZE = 32\n",
    "\n",
    "bert_config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
    "input_files = tf.io.gfile.glob(os.path.join(pretraining_data_dir,'*tfrecord'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_record_to_memory(input_files,\n",
    "                        max_seq_length = 128,\n",
    "                        max_predictions_per_seq = 20,\n",
    "                        num_cpu_threads = 4,\n",
    "                        batch_size = MINI_BATCH_SIZE):\n",
    "    \n",
    "    d = tf.data.TFRecordDataset(input_files)\n",
    "\n",
    "    name_to_features = {\n",
    "        \"input_ids\":\n",
    "            tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "        \"input_mask\":\n",
    "            tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "        \"segment_ids\":\n",
    "            tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "        \"masked_lm_positions\":\n",
    "            tf.io.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
    "        \"masked_lm_ids\":\n",
    "            tf.io.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
    "        \"masked_lm_weights\":\n",
    "            tf.io.FixedLenFeature([max_predictions_per_seq], tf.float32),\n",
    "        \"next_sentence_labels\":\n",
    "            tf.io.FixedLenFeature([1], tf.int64),\n",
    "    }\n",
    "    parsed_dataset = d.map(\n",
    "        map_func = lambda record: tf.io.parse_single_example(record, name_to_features),\n",
    "        num_parallel_calls=num_cpu_threads)\n",
    "    parsed_dataset = parsed_dataset.batch(drop_remainder=True, \n",
    "                                          batch_size=batch_size)\n",
    "    \n",
    "    return parsed_dataset\n",
    "\n",
    "def get_single_sentence_training_data(i, s):\n",
    "    input_ids = tf.boolean_mask(\n",
    "        i,\n",
    "        1-s,\n",
    "        axis=None,\n",
    "        name='boolean_mask')\n",
    "    x = tf.slice(input_ids, [1], [input_ids.shape[0]-2], name='x')\n",
    "    x = tf.pad(x, [[0, 128-input_ids.shape[0]+2]], \"CONSTANT\", constant_values=0)\n",
    "    y = input_ids[-2]\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          2016192   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 31503)             4063887   \n",
      "=================================================================\n",
      "Total params: 6,178,895\n",
      "Trainable params: 6,178,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "model.add(layers.Embedding(input_dim=len(vocab_to_id), output_dim=64))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units and softmax activation.\n",
    "model.add(layers.Dense(len(vocab_to_id), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "    \n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), #tf.keras.loss\n",
    "              optimizer='adam', #tf.keras.optimizers\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "Fail to find the dnn implementation. [Op:CudnnRNN]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-79d205788237>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    254\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    959\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcan_use_gpu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m           last_output, outputs, new_h, new_c, runtime = cudnn_lstm(\n\u001b[1;32m--> 961\u001b[1;33m               **cudnn_lstm_kwargs)\n\u001b[0m\u001b[0;32m    962\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m           last_output, outputs, new_h, new_c, runtime = standard_lstm(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcudnn_lstm\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     outputs, h, c, _ = gen_cudnn_rnn_ops.cudnn_rnn(\n\u001b[0;32m   1173\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_h\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_c\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m         rnn_mode='lstm')\n\u001b[0m\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m   \u001b[0mlast_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn\u001b[1;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0minput_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             ctx=_ctx)\n\u001b[0m\u001b[0;32m    110\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn_eager_fallback\u001b[1;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx)\u001b[0m\n\u001b[0;32m    196\u001b[0m   \"is_training\", is_training)\n\u001b[0;32m    197\u001b[0m   _result = _execute.execute(b\"CudnnRNN\", 4, inputs=_inputs_flat,\n\u001b[1;32m--> 198\u001b[1;33m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[0;32m    199\u001b[0m   _execute.record_gradient(\n\u001b[0;32m    200\u001b[0m       \"CudnnRNN\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mc:\\users\\usherwoodpe\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Fail to find the dnn implementation. [Op:CudnnRNN]"
     ]
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 1500  1624  3089  1581  1542  1604  2452  1530  3530    12    69  1604\n",
      "  1502  1596    14    63 27807    63  5089  1502  1603  6665 12543  1800\n",
      " 11915  1540 15672  1506  8796  1511  3132  1506  1502  1583  2877  7651\n",
      " 15086    14  1604  2494  2988  6932  2191  1502  1674  2324  2639    12\n",
      " 27056    69  6522  1563  1973    14  1501   168  2188  1624  1502  1720\n",
      "    13    63 27807    63  1547    63  1720 24468  1502    63  1547    63\n",
      "  3260    63 27807    63  1502    63  3042  1524  1502 27807    63  1547\n",
      "    63  1571  1935    63 27807  1502  1547    63  2702    13  1651  1624\n",
      "  1551    70    13  1639    63 27807  1502  1547    63  3260    63 27807\n",
      "    63  1547    63  5170  1530  1502 27807    63  1547  1502  5651  2965\n",
      "  1502 27807    63  5089    63  1502  1604  1501], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 1500    63 27807    63  5089  1502  1603  1502  3185  3213  3378  6323\n",
      "  1502  3378  1846    14  2963  7223    14  2571 15475    14  1651  2452\n",
      "    14  2452  7047  2625  1505  1604  1563  2311    14  1501 24872 26574\n",
      "  1674  7397    12  1604  4337  1502  6040    14  2452 10721    14    63\n",
      " 27807    63  5089    63  1603 23493  4961    65  1502  1542  1604  2425\n",
      "  1621  2566  1502  2938  1542  1604  4819    63 27807    63  5089    63\n",
      " 14036  1625    63  9602    79    81  1639  1861  2273  2521    63 27807\n",
      " 14909  1502    63  1603  1502  1790  3169  8270    69  2671  3134    79\n",
      "  5394  1683    84    14  1508 13420  1557    19    66  1502  1535    63\n",
      " 27807    63  5089    63  1530  1604  3554  3074  1566  3201  2676 12873\n",
      "    79  1502  1502  1661  1502    12    79  1501], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 1500  1683  1502    14  1508    72  2904  8222    16    70    16  9693\n",
      "  1502 27807    63  1502    63  1534  1502    12  1604  3134  1542  3901\n",
      "   168  1656  3343  1542  2212    31  1501    63  1547    63  6531    63\n",
      " 27807    63  1547    63  1676    63 27807    63  1547 16981  5803    12\n",
      "    63 27807    63  1547    63  3698    63 27807    63  1547    63  4579\n",
      "    65    63  1502    63  1547    63  2638  1502  2059  1604  5499    63\n",
      "  1696    63  1502  1502    63    31  1603  1548  8026  1505  9011  3050\n",
      "  5095  8245  1502 27807    63  1547  1502  2680  1502  1683    84    14\n",
      "  1508 14945    63 27807    63  5089  1502  5867  1550  1648    65    63\n",
      "    66  1639  1796  1502    79  4937  4978 24340  1661 19846    63 27807\n",
      " 27766  5089    63  1603 19791  1502    12  1501], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 1500 30538  4469  1502    90    63 27807    63  5089    63  1603 19358\n",
      "  1534  7628  1541    69  1936  1563  1604  1502  1624 21570  2132  2469\n",
      "  3867 26907  1661  1506  1731  4342  1536  2165  2300  1505  2451  9288\n",
      "  1534  1502    63 27807    63  1547    63 12626  2704  1604  1502  1502\n",
      "  2012  8634 22469  8694 14627  2465  1683    84    14  1508    74  1569\n",
      "  8342  1502  1708    63  1502  1502  5089    63  1624  1502  4927  2242\n",
      "  1502  1501  3891 27092  5990  1502    63  5739  1502 27807    63  5089\n",
      "    63  8698 16832  1502  3214  2132  3698  5937  3214  1502  2702  1563\n",
      "  1542  1639  2668  1895  1893  5571    63  1502  1502  5089    63  1530\n",
      "  1604  3554  1574  1566  5777  1536  1566  3201  7268  1553  3505  5114\n",
      "  1542  1873  3515    12  2059  2291    31  1501], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 1500  1603  2280  8100  1536    65 10137    81  3544  1540 11634    63\n",
      " 27807    63  1547  1502  2680  1502  1683    84    14  1508  1502    72\n",
      "    63  1502  1502  5089    63  1502  9996 14165  1530  1516  1892  3493\n",
      " 26274  1502  1566  5333  1604  1861 11109  1762    31  1501 16065  1553\n",
      "  1624  2254  2808    12  1502  1511  2280  1841  1502 27807    63  5089\n",
      "    63  1502  1717  1502  3127  1505  1621  1524  5440  3329    12  1639\n",
      "   168  3486  1651  2792  1824  2958    63 27807    63  1502  1502  1603\n",
      "  1519  2911  1524 21242  1790  1624  2145  2242  1848    79 21056  1502\n",
      "  1542  1624 13362  1534  2947  1583  5998  1518  6332    69  1624  3595\n",
      "  4614    12  1502  1502  1530 15188  2287  2433  1534 12703    69  1945\n",
      "  3084  1663  2452  1656  6262  4978  2204  1501], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 1500  2473  1731  1604     1  1683    84 14178  1508    68  3033  6692\n",
      "  2726  1502  1502 27807    63  1502    63  1502  7626  6837  1604  4819\n",
      "  1548  5629  1502  2351  1502  1638  6796 17443    14  1501  1502 27807\n",
      "    63  1502  1502  1603 25199    79  1542  3286  1518  1604  1965  1624\n",
      "    12  1502  6778  3173  1502  1502    12  2771  1542  1796  7737  1505\n",
      "  4934  2220 10867 28350    65  1661  5065    63 27807    63  9741    63\n",
      "  1603  6079  6758    63 22500  1943    13  8205 24965  1604  1542  1630\n",
      "  1542 14309 16323  1663  1506  3138  1629  8487  1502 27807    63  5089\n",
      "    63  1603 12278  1873    63 27807  1502  1547    63  1542  1541    63\n",
      " 27807    63  1547    63  4226    63 27807  1502  1547    63  5482    63\n",
      " 27807    63  1547    63  6531    63 27807  1501], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 1500  1502  1642  1502  1502  1690  1707  1683    84    14  1508  2654\n",
      "    77  1502  5319  1502  8627    18    63 27807    63  5089  1502  1603\n",
      " 17495  1604   168  1548  2142  1974  1711  1502    14  1501  1780  1798\n",
      "    19  1772 16332    63  1502    63  5089    63    66 13420  7942  2116\n",
      "    87  1502  1630  3716    63 27807    63  5089    63  1603  7103  1610\n",
      "  1639  1796    31  1683    84    14  1508    77  3990 12321    25  5386\n",
      "  3878    63 27807    63  1502    63  1603  1502  1906 27270 14825  1639\n",
      "  7295  2409  6722   168  2348  2671  1502  2212    12  4111  1566  8254\n",
      "  7512  1718  1536  1566 18452  1505  4734  1502  1689    63 27807  1502\n",
      "  5089    63  1603  6570  1502  5078  1604  5277  1542    65  1994   168\n",
      "  3343  1731  1604    12  1502  1735  1502  1501], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 1500  1694  9374    16 26139    23  7929    63 27807    63  1502    63\n",
      "  1502  5513  1542 23973  1731  1964    31  1502  1502  1731  1604  1542\n",
      "  1502    65  6455  1553  1542  1873  6167  2644  1548  1902    63 27807\n",
      "    63  1547    63  2452  6809  1661  2277  1505 18800    63  1502    63\n",
      "  1697    67    63    14  1683    84    14  2120    74    16  2744  1502\n",
      "    21  1502  2650    63 27807    63  5089    63 20559  2249    73  2704\n",
      "  1604  1502  1583 27409  1502  3417  2165  6075    31  1502  1501  3643\n",
      "  1506  2324  1505  2409  1542  1873  1596 11042  3343  1731  1604    69\n",
      "  9738  1542  1621  3665  1683    84    14  1502    80  2116    65  1502\n",
      "  1502  4146    63 27807    63  5089    63  1603  1502  5760    63  7965\n",
      "  1502  1696    63  1697    67    63    14  1501], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 1500    14  1508  1782    81 10238 13262  1502    84  1502 27807    63\n",
      "  5089    63  1502  1505  5125  1731  5125  8930    13  1502  1604  1621\n",
      "  5331  1542  1760  1674  6297  2704  1674  6297   168  2521  1502  1696\n",
      "    63  1697    67    63     1  3475  6297    72 13486 12716   168    79\n",
      " 23655  1674  6297   168  2521 13550  2533  1552  1502    84    14  1508\n",
      "  1711    87  1502    85  1501  1796  1502 27807    63  1547    63  6492\n",
      "  1683    84    14  1508  1967 15856 10276  7586    23    75    63 27807\n",
      "    63  5089    63  1603  3902  1502  1590 11275  2612  1542 21468 14996\n",
      "   168  8579  1761  1502  2452 12927 24075    13  4878  1661  3286 20425\n",
      "    13 11453 17155  1553    13  3670 13521 12128  5610  1502  4934 22281\n",
      "  1502  1502  1604  1621  3159  6778 22121  1501], shape=(128,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 1500  1530  1604  1502  3539  1711  2808    12  1624  1502  1524 11608\n",
      "  1711  2452  1656    14  1501  5524 13978    79    65  1661 15246 21667\n",
      "  1502  1502  1505  3599  1502  1604  1502  2059  1639  2223  1683    84\n",
      "    14  1502  1502  3243 10026  3366 14432    63 27807    63  5089    63\n",
      "  1603  1502 10811  1502  1639  1513 19379  1536  1516  9305  1511  4275\n",
      "    12  1502  1502  1502    63 27807    63  1547    63  1519  1502    12\n",
      "  1511  4054    12  1536    65  5325 16845  1542  1557 13295    79 23859\n",
      "    12  7267  1542  1530  1502 15898  1635  2783  1861  1502  1731  4123\n",
      "  1683    84  1502  1508    18    66 28309 10460  7409    63 27807    63\n",
      "  5089    63  1604  1621  3173  1574  4822 27345  1581  2901  1536  2478\n",
      "    12  1530  1604  1635 18369    12  1663  1501], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for bn, batch in enumerate(parsed_dataset.repeat().batch(MINI_BATCH_SIZE).take(MINI_BATCH_SIZE)):\n",
    "    X = []\n",
    "    Y = []\n",
    "    ips = batch['input_ids']\n",
    "    sms = batch['segment_ids']\n",
    "    for i, s in zip(ips, sms):\n",
    "        x, y = get_single_sentence_training_data(i, s)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    X = tf.stack(X)\n",
    "    Y = tf.stack(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
